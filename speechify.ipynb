{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speechify.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lMW_ALL7-Nd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c45a362b-b5ff-4987-84dc-7539be5ea051"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "### Helper Functions\n",
        "\n",
        "def strip_string(str):\n",
        "\tclean_str = str.replace(\"'\", \"\")\n",
        "\tclean_str = clean_str.replace(\"’\", \"\")\n",
        "\tclean_str = clean_str.replace(\"“\", \"\")\n",
        "\tclean_str = clean_str.replace(\"”\", \"\")\n",
        "\tclean_str = clean_str.replace(\"  \", \" \")\n",
        "\tclean_str = clean_str.replace('\"', \"\")\n",
        "\tclean_str = clean_str.replace(\"(\", \"\")\n",
        "\tclean_str = clean_str.replace(\")\", \"\")\n",
        "\tclean_str = clean_str.replace(\".\", \" .\")\n",
        "\tclean_str = clean_str.replace(\"&\", \"\")\n",
        "\t#clean_str = clean_str.replace(\"-\", \"\")\n",
        "\tclean_str = clean_str.replace(\"_\", \"\")\n",
        "\tclean_str = clean_str.replace(\"—\", \", \")\n",
        "\tclean_str = clean_str.replace(\",\", \" ,\")\n",
        "\t\n",
        "\treturn clean_str\n",
        "\n",
        "\n",
        "def newPage():\n",
        "\tprint(\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
        "\t\n",
        "\n",
        "text = open(\"/content/Markov/bush.txt\", \"r\").read().lower()\n",
        "\n",
        "\n",
        "text =  strip_string(text)\n",
        "\n",
        "text_list = text.split(\" \")\n",
        "\n",
        "unique_words = []\n",
        "\n",
        "for word in text_list:\n",
        "  if word not in unique_words:\n",
        "    unique_words.append(word)\n",
        "\n",
        "unique_words_dict = { word : i for i, word in enumerate(unique_words) }\n",
        "unique_words_dict2 = { i : word for i, word in enumerate(unique_words) }\n",
        "\n",
        "frequency_matrix = np.zeros((len(unique_words), len(unique_words)))\n",
        "\n",
        "for i in range(len(text_list)-1):\n",
        "  current_word = text_list[i]\n",
        "  next_word = text_list[i+1]\n",
        "  frequency_matrix[unique_words_dict[current_word], unique_words_dict[next_word]] += 1\t\n",
        "\n",
        "likelihood_matrix = frequency_matrix.copy()\n",
        "for row in range(frequency_matrix.shape[0]):\n",
        "  if np.sum(frequency_matrix[row]) != 0:\n",
        "    likelihood_matrix[row] /= np.sum(frequency_matrix[row])\n",
        "\n",
        "M = likelihood_matrix\n",
        "\n",
        "next = unique_words_dict[\".\"]\n",
        "\n",
        "response = \"\\n\"\n",
        "while response[-1] != \".\" and response != \"!\" and response[-1] != \"?\":\n",
        "  next = np.random.choice(len(M[next]), 1, p=M[next])[0]\n",
        "  if unique_words_dict2[next] == \".\" or unique_words_dict2[next] == \",\":\n",
        "    response = response + unique_words_dict2[next]\n",
        "  else:\n",
        "    response = response + \" \" + unique_words_dict2[next]\n",
        "\n",
        "print(response)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " at west point graduate, however, and crime to help during which parents can read at least 20 ,000 agents and we learn, i had his nuclear weapon, i will make that iraq has chosen to win the only chance to leave the terrorists such weapons.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9p4k_WJd9C8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv6IHMvoeaaM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}